{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "testing mode vs. validation mode : sliding window的取樣窗口略有不同，另外validation mode有offline validation，而testing mode則會存出預測結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "pred_class = ['2', '6', '10', '12', '13', '15', '18', '19', '21', '22', '25', '26', '36', '37', '39', '48']\n",
    "idx_to_class = {i:class_ for i, class_ in enumerate(pred_class)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extra features from raw_data\n",
    "從原始資料中萃取額外特徵並後續放入模型，包含50萬名用戶的個人特徵(取最後一筆有效資料)以及前19個月最常使用的卡號特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_dat = pd.read_csv('tbrain_cc_training_48tags_hash_final.csv', usecols = ['chid', 'dt',\n",
    "                                                                             'masts', 'educd', 'trdtp', 'naty', 'poscd', 'cuorg', 'slam',\n",
    "                                                                             'gender_code', 'age', 'primary_card'])\n",
    "\n",
    "customer_dat = cu_dat.groupby('chid').tail(1).drop(columns = 'dt').sort_values('chid')\n",
    "del cu_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mode card -v2\n",
    "use_cols = ['dt', 'chid', 'shop_tag',\n",
    "            'card_1_txn_cnt', 'card_2_txn_cnt', 'card_3_txn_cnt', 'card_4_txn_cnt', 'card_5_txn_cnt',\n",
    "            'card_6_txn_cnt', 'card_7_txn_cnt', 'card_8_txn_cnt', 'card_9_txn_cnt', 'card_10_txn_cnt',\n",
    "            'card_11_txn_cnt', 'card_12_txn_cnt', 'card_13_txn_cnt', 'card_14_txn_cnt', 'card_other_txn_cnt',]\n",
    "\n",
    "card_df = pd.read_csv('tbrain_cc_training_48tags_hash_final.csv', usecols=use_cols)\n",
    "\n",
    "# take only month before 18 # test->19\n",
    "card_df = card_df[card_df.dt<19]\n",
    "\n",
    "# 不精準的卡片使用率計算方式，單純加總各個shop_tag下的消費次數之後取最大值\n",
    "pct_sum = card_df.groupby(['chid', 'shop_tag']).sum()\n",
    "pct_sum['max_card_idx'] = np.argmax(pct_sum.values[:,1:], axis = 1)+1\n",
    "pct_sum = pct_sum[['max_card_idx']].reset_index()\n",
    "\n",
    "# long to wide\n",
    "chid_card_choose = pct_sum.pivot(index='chid', columns = 'shop_tag', values = 'max_card_idx').fillna(0)\n",
    "chid_card_choose = chid_card_choose[pred_class]\n",
    "\n",
    "del card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將每個用戶常使用的卡號放進 customer_dat中   (未做sliding window處理)\n",
    "customer_dat = customer_dat.merge(chid_card_choose, left_on='chid', right_index=True, how = 'left').fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load processed data\n",
    "載入前處理後的資料並且以sliding window分割資料。由於前處理的資料有三份，在此將會分別讀取三份資料並執行相同的步驟，最後再使用三份資料產生的模型預測結果做averaging。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cnt_amt_card_onoff_doov_data.csv')\n",
    "\n",
    "# data = pd.read_csv('data/cnt_amt_card_cnt_onoff_doov_cnt_data.csv')\n",
    "# data = pd.read_csv('data/cnt_amt_card_onoff_doov_cnt_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chid = data['chid']\n",
    "data = data.drop(columns = ['chid'])\n",
    "\n",
    "n_features = 7\n",
    "n_class = len(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation mode\n",
    "\n",
    "X_train = np.vstack([\n",
    "    data.iloc[:,n_class*n_features*0:-n_class*n_features*7],\n",
    "    data.iloc[:,n_class*n_features*1:-n_class*n_features*6],\n",
    "    data.iloc[:,n_class*n_features*2:-n_class*n_features*5],\n",
    "    data.iloc[:,n_class*n_features*3:-n_class*n_features*4],\n",
    "    data.iloc[:,n_class*n_features*4:-n_class*n_features*3],\n",
    "    data.iloc[:,n_class*n_features*5:-n_class*n_features*2]\n",
    "])\n",
    "y_train=  np.vstack([\n",
    "    data[[f\"txn_amt_dt18_shoptag_{i}\" for i in pred_class]],\n",
    "    data[[f\"txn_amt_dt19_shoptag_{i}\" for i in pred_class]],\n",
    "    data[[f\"txn_amt_dt20_shoptag_{i}\" for i in pred_class]],\n",
    "    data[[f\"txn_amt_dt21_shoptag_{i}\" for i in pred_class]],\n",
    "    data[[f\"txn_amt_dt22_shoptag_{i}\" for i in pred_class]],\n",
    "    data[[f\"txn_amt_dt23_shoptag_{i}\" for i in pred_class]]\n",
    "])\n",
    "\n",
    "y_train_class =  np.where(y_train>0, 1, 0)\n",
    "X_test = data.iloc[:, n_class*n_features*6:-n_class*n_features*1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature engineering on sliding window\n",
    "針對sliding window製作額外特徵，並且合併第二步的額外特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_zeros = X_train.mean(axis = 1)>0\n",
    "y_train = y_train[not_zeros]\n",
    "y_train_class = y_train_class[not_zeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(X):\n",
    "    '''\n",
    "    txn_amt_dt{m}_shoptag_{n}, txn_cnt_dt{m}_shoptag_{n}, ...\n",
    "    '''\n",
    "    \n",
    "    # total amt & cnt\n",
    "    avg_dt_amt = np.mean(X[:,::n_features], axis = 1).reshape(-1, 1)\n",
    "    recent_avg_dt_amt = np.mean(X[:,-n_class*n_features*3::n_features], axis = 1).reshape(-1, 1)\n",
    "    avg_dt_cnt = np.mean(X[:,1::n_features], axis = 1).reshape(-1, 1)\n",
    "    recent_avg_dt_cnt = np.mean(X[:,-n_class*n_features*3+1::n_features], axis = 1).reshape(-1, 1)\n",
    "    \n",
    "    std_dt_amt = np.std(X[:,::n_features], axis = 1).reshape(-1, 1)\n",
    "    recent_std_dt_amt = np.std(X[:,-n_class*n_features*3::n_features], axis = 1).reshape(-1, 1)\n",
    "    std_dt_cnt = np.std(X[:,1::n_features], axis = 1).reshape(-1, 1)\n",
    "    recent_std_dt_cnt = np.std(X[:,-n_class*n_features*3+1::n_features], axis = 1).reshape(-1, 1)\n",
    "    \n",
    "\n",
    "    # amt & cnt by shoptag\n",
    "    shoptag_avg_amt = np.array([np.mean(X[:,shoptag*n_features::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "    shoptag_avg_cnt = np.array([np.mean(X[:,shoptag*n_features+1::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "    \n",
    "    shoptag_std_amt = np.array([np.std(X[:,shoptag*n_features::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "    shoptag_std_cnt = np.array([np.std(X[:,shoptag*n_features+1::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "\n",
    "    amt_dt_pro = recent_avg_dt_amt / (avg_dt_amt +1)\n",
    "    cnt_dt_pro = recent_avg_dt_cnt / (avg_dt_cnt +1)    \n",
    "    \n",
    "    # offline / domestic\n",
    "    avg_dt_off_do_amt = np.mean(X[:,3::n_features], axis = 1).reshape(-1, 1)\n",
    "    avg_dt_on_do_amt = np.mean(X[:,4::n_features], axis = 1).reshape(-1, 1)\n",
    "    avg_dt_off_ov_amt = np.mean(X[:,5::n_features], axis = 1).reshape(-1, 1)\n",
    "    avg_dt_on_ov_amt = np.mean(X[:,6::n_features], axis = 1).reshape(-1, 1)\n",
    "    \n",
    "    shoptag_off_do_avg_amt = np.array([np.mean(X[:,shoptag*n_features+3::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "    shoptag_on_do_avg_amt = np.array([np.mean(X[:,shoptag*n_features+4::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "    shoptag_off_ov_avg_amt = np.array([np.mean(X[:,shoptag*n_features+5::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "    shoptag_on_ov_avg_amt = np.array([np.mean(X[:,shoptag*n_features+6::n_class], axis = 1) for shoptag in range(n_class)]).transpose()\n",
    "\n",
    "    \n",
    "    # customer_data\n",
    "    customer_ = customer_dat.drop(columns = 'chid').values\n",
    "    n_customer = customer_.shape[0]\n",
    "    rep = int(X.shape[0]/n_customer)\n",
    "    customer_ = np.tile(customer_, reps=(rep, 1))\n",
    "    \n",
    "    X_fe = np.concatenate([X, avg_dt_amt, recent_avg_dt_amt, avg_dt_cnt, recent_avg_dt_cnt, shoptag_avg_amt, shoptag_avg_cnt,\n",
    "                           std_dt_amt, recent_std_dt_amt, std_dt_cnt, recent_std_dt_cnt, shoptag_std_amt, shoptag_std_cnt,\n",
    "                           avg_dt_off_do_amt, avg_dt_on_do_amt, avg_dt_off_ov_amt, avg_dt_on_ov_amt, shoptag_off_do_avg_amt, \n",
    "                           shoptag_on_do_avg_amt, shoptag_off_ov_avg_amt, shoptag_on_ov_avg_amt,\n",
    "                           amt_dt_pro, cnt_dt_pro,\n",
    "                           customer_], axis = 1)\n",
    "    return X_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train = feature_engineer(X_train)\n",
    "X_train = X_train[not_zeros]\n",
    "\n",
    "X_test = feature_engineer(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling\n",
    "分別建立二元分類與迴歸模型預測交易機率與交易價格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.8,\n",
    "    'n_estimators': 1000,\n",
    "}\n",
    "\n",
    "reg_model = MultiOutputRegressor(LGBMRegressor(**params)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.8,\n",
    "    'n_estimators': 1000,\n",
    "}\n",
    "\n",
    "class_model = MultiOutputClassifier(LGBMClassifier(**params)).fit(X_train, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_prediction = reg_model.predict(X_test)\n",
    "class_prediction = np.array([c[:,1] for c in class_model.predict_proba(X_test)]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Offline evaluation\n",
    "以dt24的交易資料作為validation的ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction has shape 500000x16\n",
    "submit = []\n",
    "prediction = reg_prediction*(class_prediction**1.5)\n",
    "for row in prediction:\n",
    "    submit.append(row.argsort()[-3:][::-1][np.newaxis,:])\n",
    "submit = np.vstack(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = submit.shape\n",
    "submit = submit.flatten()\n",
    "submit = np.array([idx_to_class[idx] for idx in submit])\n",
    "submit = submit.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv = pd.read_csv(\"sample_submission.csv\")\n",
    "submit_csv = submit_csv.sort_values(\"chid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv.iloc[:,1:] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate DCG score with 398988 users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7175257432488035"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import DCG\n",
    "DCG(submit_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
